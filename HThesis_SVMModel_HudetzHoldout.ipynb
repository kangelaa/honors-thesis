{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kangelaa/honors-thesis/blob/main/HThesis_SVMModel_HudetzHoldout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "permanent-calcium",
      "metadata": {
        "id": "permanent-calcium"
      },
      "source": [
        "# Honors Thesis: Classifying Consciousness\n",
        "by Angela Kan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "great-shareware",
      "metadata": {
        "id": "great-shareware"
      },
      "outputs": [],
      "source": [
        "#required imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, backend\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io as spio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm \n",
        "from statistics import mean, variance\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.utils import resample\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "#print full array setting\n",
        "np.set_printoptions(threshold=1000) #revert back to regular w/ threshold=1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "alone-vaccine",
      "metadata": {
        "id": "alone-vaccine"
      },
      "source": [
        "## Data Imports, Preprocessing, Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#access STSP .mat files from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "IpuRqGo7nOXi"
      },
      "id": "IpuRqGo7nOXi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING FOR NEW DATA (same lengths):"
      ],
      "metadata": {
        "id": "BJOtQNKlmflo"
      },
      "id": "BJOtQNKlmflo"
    },
    {
      "cell_type": "code",
      "source": [
        "#SAME LENGTH VERSION - PROPOFOL DATA\n",
        "#import files and save in dataframe, adding labels \n",
        "\n",
        "NUM_SUBJECTS=18\n",
        "NUM_SCANS=38 #25 w/o recovery data\n",
        "LARGEST_X_DIM=55\n",
        "LARGEST_Y_DIM=100\n",
        "\n",
        "#array initialized w/ 0s for image data \n",
        "all_data=np.zeros((NUM_SCANS,LARGEST_X_DIM*LARGEST_Y_DIM))\n",
        "#array initialized w/ 2s for label data (0 for wake, 1 for sleep)\n",
        "all_labels=np.ones((NUM_SCANS))*3 #initialize with 3's\n",
        "\n",
        "#iterate through each STSP\n",
        "for i in range(1,1+NUM_SCANS):\n",
        "  if i < 10:\n",
        "    mat=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/propofol_stsps/_fft_stsp_sub_00{i}.mat\")\n",
        "  else:\n",
        "    mat=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/propofol_stsps/_fft_stsp_sub_0{i}.mat\")\n",
        "  stsp = mat[\"stsp\"]\n",
        "  #cropped = stsp[:,:100]  #crop accordingly\n",
        "  flat = stsp.flatten() #remove structure for SVM input\n",
        "  all_data[i-1]=flat\n",
        "\n",
        "  # #create labels dataframe\n",
        "  # if i % 2 == 0: # even=wakefulness state, add label [0]\n",
        "  #   all_labels[i-1]=0\n",
        "  # else: # odd=sleep state, add label [1] \n",
        "  #   all_labels[i-1]=1\n",
        "\n",
        "\n",
        "#reshape to be 4dim from 3dim\n",
        "#all_data=np.reshape(all_data,(NUM_SUBJECTS*2,LARGEST_X_DIM,LARGEST_Y_DIM,1))"
      ],
      "metadata": {
        "id": "JXkO0Et1mie1"
      },
      "id": "JXkO0Et1mie1",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAME LENGTH VERSION - HUDETZ DATA\n",
        "#import files and save in dataframe, adding labels \n",
        "\n",
        "NUM_SCANS=43 \n",
        "LARGEST_X_DIM=55\n",
        "LARGEST_Y_DIM=100\n",
        "\n",
        "#array initialized w/ 0s for image data \n",
        "all_test_data=np.zeros((NUM_SCANS,LARGEST_X_DIM*LARGEST_Y_DIM))\n",
        "#array initialized w/ 2s for label data (0 for wake, 1 for sleep)\n",
        "all_test_labels=np.ones((NUM_SCANS))*3 #initialize with 3's\n",
        "\n",
        "#iterate through each STSP\n",
        "for i in range(1,1+NUM_SCANS):\n",
        "  if i < 10:\n",
        "    mat=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/hudetz_stsps/_fft_stsp_sub_00{i}.mat\")\n",
        "  else:\n",
        "    mat=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/hudetz_stsps/_fft_stsp_sub_0{i}.mat\")\n",
        "  stsp = mat[\"stsp\"]\n",
        "  #cropped = stsp[:,:100]  #crop accordingly\n",
        "  flat = stsp.flatten() #remove structure for SVM input\n",
        "  all_test_data[i-1]=flat"
      ],
      "metadata": {
        "id": "OeKK_XB7_LaB"
      },
      "id": "OeKK_XB7_LaB",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set HUDETZ labels based on info\n",
        "info_hud=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/hudetz_stsps/_fft_info.mat\")\n",
        "#recovery_hud = []\n",
        "wake_hud=[]\n",
        "unconscious_hud=[]\n",
        "for i, name in enumerate(info_hud[\"fft4info\"][\"images\"][0][0]):\n",
        "  if 'Wakefulness' in str(name[0]):\n",
        "    all_test_labels[i]=0\n",
        "    wake_hud.append(i)\n",
        "  elif 'DeepSedation' in str(name[0]):\n",
        "    all_test_labels[i]=1\n",
        "    unconscious_hud.append(i)\n",
        "  # elif 'W2' in str(name[0]):\n",
        "  #   all_labels[i]=2 #make 0 or 2 depending on # of classes desired\n",
        "  #   recovery_hud.append(i)"
      ],
      "metadata": {
        "id": "Yyrin8x-Mi4Y"
      },
      "id": "Yyrin8x-Mi4Y",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set PROPOFOL labels based on info\n",
        "info_prop=spio.loadmat(f\"/content/gdrive/MyDrive/2022-23/Honors Thesis/propofol_stsps/_fft_info.mat\")\n",
        "recovery_prop = []\n",
        "wake_prop=[]\n",
        "unconscious_prop=[]\n",
        "for i, name in enumerate(info_prop[\"fft4info\"][\"images\"][0][0]):\n",
        "  if 'W1' in str(name[0]):\n",
        "    all_labels[i]=0\n",
        "    wake_prop.append(i)\n",
        "  elif 'S2' in str(name[0]):\n",
        "    all_labels[i]=1\n",
        "    unconscious_prop.append(i)\n",
        "  elif 'W2' in str(name[0]):\n",
        "    all_labels[i]=2 #make 0 or 2 depending on # of classes desired\n",
        "    recovery_prop.append(i)"
      ],
      "metadata": {
        "id": "1hbQzzY-noOQ"
      },
      "id": "1hbQzzY-noOQ",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop prop recovery data if desired (for more balanced dataset)\n",
        "for scan in info_hud[\"fft4info\"][\"images\"][0][0]:\n",
        "  print(scan[0])\n",
        "\n",
        "#print(recovery_prop)\n",
        "\n",
        "all_data=np.delete(all_data,recovery_prop,axis=0)\n",
        "all_labels=np.delete(all_labels,recovery_prop,axis=0)\n"
      ],
      "metadata": {
        "id": "mf3AIO1p11eU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c38021-e6a1-48d5-9314-1dd58ef4c634"
      },
      "id": "mf3AIO1p11eU",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P1_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P2_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P2_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P3_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P3_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P4_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P5_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P6_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P6_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P7_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P7_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P11_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P11_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P12_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P13_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P13_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P14_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P28_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P29_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P29_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P30_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P31_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C1_P31_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P1_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P2_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P3_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P3_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P4_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P6_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P6_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P7_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P7_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P11_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P12_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P12_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P13_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P13_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P14_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P14_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P28_Wakefulness_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P29_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P31_DeepSedation_res2std.nii']\n",
            "['/Volumes/T7Shield/Hudetz_STSP/res2std_cropped/C2_P31_Wakefulness_res2std.nii']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset index for each class\n",
        "wake_prop=[]\n",
        "unconscious_prop=[]\n",
        "for i, name in enumerate(all_labels):\n",
        "  if name==0:\n",
        "    #all_labels[i]=0\n",
        "    wake_prop.append(i)\n",
        "  elif name==1:\n",
        "    #all_labels[i]=1\n",
        "    unconscious_prop.append(i)\n"
      ],
      "metadata": {
        "id": "C2imWIJTPkZt"
      },
      "id": "C2imWIJTPkZt",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSAMPLING"
      ],
      "metadata": {
        "id": "pPP6lc9KM8p4"
      },
      "id": "pPP6lc9KM8p4"
    },
    {
      "cell_type": "code",
      "source": [
        "#DROP unusable subjects from data\n",
        "# DROP_sub = [7,8,9,10,13,14,17,18,19,20,21,22,27,28,31,32,33,34]\n",
        "# DROP_bad = #[8,10,18,19,21,22,27,28,31,32,33] #THESE SHOULD BE MOVED BACK ONE INDEX? 0-indexing (CHECK ORDER AGAIN, added in order of info.mat)\n",
        "\n",
        "# all_data=np.delete(all_data,DROP_bad,axis=0)\n",
        "# all_labels=np.delete(all_labels,DROP_bad,axis=0)\n",
        "\n",
        "#BALANCE TRAIN DATA \n",
        "drop_prop_wake=resample(wake_prop,replace=False,n_samples=3)\n",
        "#DROP_bad = [17,19,22]\n",
        "#DROP_bad = #[8,10,18,19,21,22,27,28,31,32,33] #THESE SHOULD BE MOVED BACK ONE INDEX? 0-indexing (CHECK ORDER AGAIN, added in order of info.mat)\n",
        "\n",
        "all_data=np.delete(all_data,drop_prop_wake,axis=0)\n",
        "all_labels=np.delete(all_labels,drop_prop_wake,axis=0)\n",
        "drop_prop_wake"
      ],
      "metadata": {
        "id": "ASVX5rSNFpZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de59c85-7832-4c21-a2bc-1f9bc0db0c7c"
      },
      "id": "ASVX5rSNFpZs",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 6, 19]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1#only use C2 for Hudetz test \n",
        "# all_test_data=all_test_data[:23]\n",
        "# all_test_labels=all_test_labels[:23]"
      ],
      "metadata": {
        "id": "DbNPfNPVlRGf"
      },
      "id": "DbNPfNPVlRGf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOoQzIHPfVEv"
      },
      "source": [
        "OVERSAMPLING (potential risk of overfitting?) \n",
        "\n",
        "NOTE: USING RANDOM SEED"
      ],
      "id": "kOoQzIHPfVEv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRg5MqHFfTT1"
      },
      "outputs": [],
      "source": [
        "#sample 3 more datapoints for balanced dataset\n",
        "unconscious_upsample_index = resample(unconscious_prop,replace=True, n_samples=len(wake_prop)-len(unconscious_prop),random_state=1234)\n",
        "unconscious_upsample_index\n"
      ],
      "id": "XRg5MqHFfTT1"
    },
    {
      "cell_type": "code",
      "source": [
        "unconscious_upsample_index = np.concatenate([unconscious_upsample_index,unconscious_prop])\n",
        "unconscious_upsample_index"
      ],
      "metadata": {
        "id": "54LI3jAhPBnY"
      },
      "id": "54LI3jAhPBnY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6c-ACnogXtj"
      },
      "outputs": [],
      "source": [
        "unconscious_upsample=[all_data[i] for i in unconscious_upsample_index]\n",
        "unconscious_labels=np.ones(len(unconscious_upsample))\n",
        "\n",
        "wake_data=[all_data[i] for i in wake_prop]\n",
        "wake_labels=np.zeros(len(wake_data))\n",
        "\n",
        "#unconscious_upsample,unconscious_labels,wake_data,wake_labels"
      ],
      "id": "h6c-ACnogXtj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azH1x8iHg3v0"
      },
      "outputs": [],
      "source": [
        "all_data=np.concatenate([np.array(wake_data),np.array(unconscious_upsample)])\n",
        "all_labels=np.concatenate([wake_labels,unconscious_labels])\n"
      ],
      "id": "azH1x8iHg3v0"
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels"
      ],
      "metadata": {
        "id": "n4T_jn2LuhpF"
      },
      "id": "n4T_jn2LuhpF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_data.shape,all_labels.shape)\n",
        "all_data,all_labels"
      ],
      "metadata": {
        "id": "X802Ch3jPwVb"
      },
      "id": "X802Ch3jPwVb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(all_labels),len(all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDzzVpM-CK-N",
        "outputId": "ce2a6164-4382-4af1-aff2-139e48fdad5c"
      },
      "id": "PDzzVpM-CK-N",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11.0, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_test_data.shape,all_test_labels.shape)\n",
        "all_test_data,all_test_labels"
      ],
      "metadata": {
        "id": "jFY2o1PcBHE4"
      },
      "id": "jFY2o1PcBHE4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(all_test_labels),len(all_test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBMzQOk4B4d5",
        "outputId": "b9d8883c-22f4-4a98-e72e-c9bcff0e4dd9"
      },
      "id": "vBMzQOk4B4d5",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16.0, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display STSP data"
      ],
      "metadata": {
        "id": "fjVyPJWQAGPd"
      },
      "id": "fjVyPJWQAGPd"
    },
    {
      "cell_type": "code",
      "source": [
        "# mat=spio.loadmat(\"/content/gdrive/MyDrive/2022-23/Honors Thesis/hudetz_stsps/_fft_stsp_sub_001.mat\")\n",
        "# data=mat[\"stsp\"]\n",
        "# plt.imshow(data)"
      ],
      "metadata": {
        "id": "Nu49xEIvQ2fS"
      },
      "id": "Nu49xEIvQ2fS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split into training/validation and testing, with specified test_size split and ensuring both train/test have same amount of sleep/wake data\n",
        "# TEST_SIZE=.3\n",
        "\n",
        "# #train-test split from all_data\n",
        "# x_train,x_test,y_train,y_test=train_test_split(all_data,all_labels,test_size=TEST_SIZE,stratify=all_labels)\n",
        "# print(x_train.shape,x_test.shape)\n",
        "\n",
        "#train-val split for train data\n",
        "# x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=TEST_SIZE,#random_state=1234,stratify=y_train)\n",
        "# print(x_train.shape,x_val.shape,y_train,y_val)\n",
        "# print(x_train[2])\n",
        "\n",
        "# #train-test split from all_data\n",
        "# x_train,x_test,y_train,y_test=train_test_split(all_data,all_labels,test_size=TEST_SIZE,stratify=all_labels)\n",
        "# print(x_train.shape,x_test.shape)\n",
        "\n",
        "#train-test split from all_data AND all_test_data\n",
        "x_train,x_test,y_train,y_test=all_data,all_test_data,all_labels,all_test_labels\n",
        "print(x_train.shape,x_test.shape)"
      ],
      "metadata": {
        "id": "wDwOirGJkRl-"
      },
      "id": "wDwOirGJkRl-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #normalize data: Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network.\n",
        "# x_train=np.array((x_train-np.min(x_train))/(np.max(x_train)-np.min(x_train)))\n",
        "# x_test = np.array((x_test-np.min(x_test))/(np.max(x_test)-np.min(x_test)))\n",
        "# x_train=x_train/np.std(x_train)\n",
        "# x_test=x_test/np.std(x_test)\n",
        "# x_train,x_test"
      ],
      "metadata": {
        "id": "EMEbyevVPtY0"
      },
      "id": "EMEbyevVPtY0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.imshow(mat[\"stsp\"])"
      ],
      "metadata": {
        "id": "pHq-MeN2tgm5"
      },
      "id": "pHq-MeN2tgm5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "international-option",
      "metadata": {
        "id": "international-option"
      },
      "source": [
        "Let's take a look at our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels=[\"wake\",\"unconscious\"]#,\"recovery\"]"
      ],
      "metadata": {
        "id": "MfD-dM2rJOPz"
      },
      "id": "MfD-dM2rJOPz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "handled-military",
      "metadata": {
        "id": "handled-military"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(20): #loop through grid, plot each image\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "\n",
        "  plt.imshow(x_train[i])\n",
        "  plt.xlabel(train_labels[int(y_train[i])]) #label w/ class names \n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "emerging-motion",
      "metadata": {
        "id": "emerging-motion"
      },
      "source": [
        "## Building a Model\n",
        "\n",
        "MRMR (https://towardsdatascience.com/mrmr-explained-exactly-how-you-wished-someone-explained-to-you-9cf4ed27458b) \n",
        "\n",
        "SVMS advantages (https://scikit-learn.org/stable/modules/svm.html):\n",
        "- effective in high dimensional spaces\n",
        "- effective where # of dimensions > number of samples\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install mrmr_selection \n",
        "from mrmr import mrmr_classif\n",
        "\n",
        "selected_features=mrmr_classif(x_train,y_train,K=10)"
      ],
      "metadata": {
        "id": "neGvXK400ty3"
      },
      "id": "neGvXK400ty3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave One Out Implementation"
      ],
      "metadata": {
        "id": "jGhT95ATOuk1"
      },
      "id": "jGhT95ATOuk1"
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one data point out at a time\n",
        "\n",
        "#SVM\n",
        "svm_accuracy = []\n",
        "svm_params = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  train_x = np.delete(all_data,i,axis=0)\n",
        "  train_y = np.delete(all_labels,i)\n",
        "  test_x = all_data[i]\n",
        "  test_y = all_labels[i]\n",
        "\n",
        "  param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','linear','poly']}\n",
        "  svc=svm.SVC()\n",
        "  model=GridSearchCV(svc,param_grid) #can print cv_results_ attribute of gridsearch model if desired!\n",
        "  model.fit(train_x,train_y)\n",
        "  pred = model.predict(test_x.reshape(1,-1))\n",
        "  if pred == test_y:\n",
        "    val=1\n",
        "  else:\n",
        "    val=0\n",
        "  \n",
        "  svm_accuracy.append(val)\n",
        "  svm_params.append(model.best_params_)\n",
        "\n",
        "print(\"SVM: \", mean(svm_accuracy))\n",
        "\n",
        "#DT\n",
        "dt_accuracy = []\n",
        "dt_params = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  train_x = np.delete(all_data,i,axis=0)\n",
        "  train_y = np.delete(all_labels,i)\n",
        "  test_x = all_data[i]\n",
        "  test_y = all_labels[i]\n",
        "\n",
        "  param_grid={'criterion':['gini','entropy'],'max_depth':[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
        "  tree=DecisionTreeClassifier()\n",
        "  model=GridSearchCV(tree,param_grid) #can print cv_results_ attribute of gridsearch model if desired!\n",
        "  model.fit(train_x,train_y)\n",
        "  pred = model.predict(test_x.reshape(1,-1))\n",
        "  if pred == test_y:\n",
        "    val=1\n",
        "  else:\n",
        "    val=0\n",
        "  \n",
        "  dt_accuracy.append(val)\n",
        "  dt_params.append(model.best_params_)\n",
        "\n",
        "print(\"DT: \", mean(dt_accuracy))\n",
        "\n",
        "#KNN\n",
        "knn_accuracy = []\n",
        "knn_params = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  train_x = np.delete(all_data,i,axis=0)\n",
        "  train_y = np.delete(all_labels,i)\n",
        "  test_x = all_data[i]\n",
        "  test_y = all_labels[i]\n",
        "\n",
        "  param_grid={'n_neighbors':[1,2,3,4,5,6,7,8,9],'weights':['uniform','distance'],'metric':['euclidean','manhattan','minkowski']}\n",
        "  knn=KNeighborsClassifier()\n",
        "  model=GridSearchCV(knn,param_grid) #can print cv_results_ attribute of gridsearch model if desired!\n",
        "  model.fit(train_x,train_y)\n",
        "  pred = model.predict(test_x.reshape(1,-1))\n",
        "  if pred == test_y:\n",
        "    val=1\n",
        "  else:\n",
        "    val=0\n",
        "  \n",
        "  knn_accuracy.append(val)\n",
        "  knn_params.append(model.best_params_)\n",
        "\n",
        "\n",
        "print(\"KNN: \", mean(knn_accuracy))\n",
        "\n",
        "#Gaussian - no hyperparams\n",
        "nbc_accuracy = []\n",
        "#nbc_params = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  train_x = np.delete(all_data,i,axis=0)\n",
        "  train_y = np.delete(all_labels,i)\n",
        "  test_x = all_data[i]\n",
        "  test_y = all_labels[i]\n",
        "\n",
        "  #param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','linear','poly']}\n",
        "  nbc=GaussianNB()\n",
        "  #model=GridSearchCV(nbc,param_grid) #can print cv_results_ attribute of gridsearch model if desired!\n",
        "  nbc.fit(train_x,train_y)\n",
        "  pred = model.predict(test_x.reshape(1,-1))\n",
        "  if pred == test_y:\n",
        "    val=1\n",
        "  else:\n",
        "    val=0\n",
        "  \n",
        "  nbc_accuracy.append(val)\n",
        "  #nbc_params.append(model.best_params_)\n",
        "\n",
        "print(\"NBC: \", mean(nbc_accuracy))\n",
        "\n",
        "#RF\n",
        "rf_accuracy = []\n",
        "rf_params = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  train_x = np.delete(all_data,i,axis=0)\n",
        "  train_y = np.delete(all_labels,i)\n",
        "  test_x = all_data[i]\n",
        "  test_y = all_labels[i]\n",
        "\n",
        "  n_estimators = [90,100,115,130]\n",
        "  # Number of features to consider at every split\n",
        "  max_features = ['auto', 'log2']\n",
        "  # Maximum number of levels in tree\n",
        "  max_depth = [2, 10, 15, 20]\n",
        "  # Minimum number of samples required to split a node\n",
        "  min_samples_split = [2, 5, 10]\n",
        "  # Minimum number of samples required at each leaf node\n",
        "  min_samples_leaf = [1, 2, 4]\n",
        "  # Method of selecting samples for training each tree\n",
        "  criterion = ['gini','entropy']\n",
        "  # Create the random grid\n",
        "  param_grid = {'n_estimators': n_estimators,\n",
        "                'max_features': max_features,\n",
        "                'max_depth': max_depth,\n",
        "                'min_samples_split': min_samples_split,\n",
        "                'min_samples_leaf': min_samples_leaf,\n",
        "                'criterion': criterion}\n",
        "  \n",
        "  rf=RandomForestClassifier()\n",
        "  model=RandomizedSearchCV(rf,param_grid) #can print cv_results_ attribute of gridsearch model if desired!\n",
        "  model.fit(train_x,train_y)\n",
        "  pred = model.predict(test_x.reshape(1,-1))\n",
        "  if pred == test_y:\n",
        "    val=1\n",
        "  else:\n",
        "    val=0\n",
        "  \n",
        "  rf_accuracy.append(val)\n",
        "  rf_params.append(model.best_params_)\n",
        "\n",
        "print(\"RF: \", mean(rf_accuracy))"
      ],
      "metadata": {
        "id": "AdEWXIvUOtwk"
      },
      "id": "AdEWXIvUOtwk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM: \", mean(svm_accuracy))\n",
        "print(\"DT: \", mean(dt_accuracy))\n",
        "print(\"KNN: \", mean(knn_accuracy))\n",
        "print(\"NBC: \", mean(nbc_accuracy))\n",
        "print(\"RF: \", mean(rf_accuracy))"
      ],
      "metadata": {
        "id": "CvvasdAj2HDO"
      },
      "id": "CvvasdAj2HDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM: \", svm_params)\n",
        "print(\"DT: \", dt_params)\n",
        "print(\"KNN: \", knn_params)\n",
        "#print(\"NBC: \", nbc_params)\n",
        "print(\"RF: \", rf_params)"
      ],
      "metadata": {
        "id": "LxbfCe4HEpKq"
      },
      "id": "LxbfCe4HEpKq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run1 = [{'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}]\n",
        "run2 = [{'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}]\n",
        "run3 = [{'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}]\n",
        "run4 = [{'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 1, 'gamma': 1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 1, 'gamma': 1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}]\n",
        "run5 = [{'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}]"
      ],
      "metadata": {
        "id": "_LZVzplxmXLc"
      },
      "id": "_LZVzplxmXLc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svmparams = pd.concat([pd.DataFrame(run1),pd.DataFrame(run2),pd.DataFrame(run3),pd.DataFrame(run4),pd.DataFrame(run5)])"
      ],
      "metadata": {
        "id": "D7gtocHTmpvG"
      },
      "id": "D7gtocHTmpvG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(run2).mode()"
      ],
      "metadata": {
        "id": "rG8JhLJ-m2-K"
      },
      "id": "rG8JhLJ-m2-K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spoken-bahamas",
      "metadata": {
        "id": "spoken-bahamas"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm \n",
        "#cross validates across SVM model parameters to get best one\n",
        "\n",
        "\n",
        "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','linear','poly']}\n",
        "\n",
        "svc=svm.SVC()\n",
        "model=GridSearchCV(svc,param_grid)\n",
        "\n",
        "model.fit(x_train,y_train)\n",
        "model.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm \n",
        "\n",
        "SVC=svm.SVC(C=10,gamma=.0001,kernel='linear')\n",
        "SVC.fit(x_train,y_train)\n",
        "\n",
        "y_pred=SVC.predict(x_test)\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['wakefulness','deep sedation'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred,target_names=['wakefulness','deep sedation']))"
      ],
      "metadata": {
        "id": "60PvjXeLpr4P"
      },
      "id": "60PvjXeLpr4P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def f_importances(coef, names):\n",
        "#   \"\"\"\n",
        "#   PLOTS all features by importance for linear SVM\n",
        "#   \"\"\"\n",
        "\n",
        "#     imp = coef\n",
        "#     imp,names = zip(*sorted(zip(imp,names)))\n",
        "#     plt.barh(range(len(names)), imp, align='center')\n",
        "#     plt.yticks(range(len(names)), names)\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "w_o7iJAgHu3g"
      },
      "id": "w_o7iJAgHu3g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f_importances(SVC.coef_[0],features)"
      ],
      "metadata": {
        "id": "MGcKVliiIWhs"
      },
      "id": "MGcKVliiIWhs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=np.arange(5500)\n",
        "features"
      ],
      "metadata": {
        "id": "QZcsVoEJH_Ev"
      },
      "id": "QZcsVoEJH_Ev",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(abs(SVC.coef_[0]), index=features).nlargest(10).plot(kind='barh')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "leizEVTKHFML"
      },
      "id": "leizEVTKHFML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only works for linear SVC\n",
        "#SVC.coef_ "
      ],
      "metadata": {
        "id": "7U3PkeLoRccS"
      },
      "id": "7U3PkeLoRccS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross validate data to determine best max_depth parameter\n",
        "from sklearn import tree\n",
        "# N=30 #largest max_depth\n",
        "# training_scores=np.zeros(N)\n",
        "# testing_scores=np.zeros(N)\n",
        "# depths=np.arange(1,31)\n",
        "\n",
        "\n",
        "# for d in range(1, 30):\n",
        "#     T = tree.DecisionTreeClassifier(max_depth = d)\n",
        "#     T.fit(x_train, y_train)\n",
        "#     training_scores[d-1]=T.score(x_train,y_train)\n",
        "#     testing_scores[d-1]=T.score(x_test,y_test)\n",
        "# print(training_scores,testing_scores)\n",
        "    \n",
        "    \n",
        "# fig, ax = plt.subplots(1, figsize = (10, 7))\n",
        "    \n",
        "# ax.scatter(depths,training_scores,color=\"black\",label=\"training\")\n",
        "# ax.scatter(depths,testing_scores,color=\"firebrick\",label=\"testing\")    \n",
        "# ax.set(xlabel = \"Complexity (depth)\", ylabel = \"Performance (score)\",ylim=(.73,1))\n",
        "# ax.legend()\n",
        "\n",
        "T = tree.DecisionTreeClassifier()\n",
        "\n",
        "max_depth = range(1,15)\n",
        "# Create the random grid\n",
        "random_grid = {'max_depth': max_depth}\n",
        "grid_search=GridSearchCV(T,param_grid=random_grid)\n",
        "grid_search.fit(x_train,y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "n0n40Uj-3ti9"
      },
      "id": "n0n40Uj-3ti9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "T=tree.DecisionTreeClassifier(max_depth=4)\n",
        "T.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "eC94Ijk72hMY"
      },
      "id": "eC94Ijk72hMY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=T.predict(x_test)\n",
        "accuracy_score(y_pred,y_test)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['wakefulness','deep sedation'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred,target_names=['wakefulness','deep sedation']))"
      ],
      "metadata": {
        "id": "OXonWKP32um0"
      },
      "id": "OXonWKP32um0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#cross validate data to determine best max_depth parameter\n",
        "\n",
        "# N=10 #largest max_depth\n",
        "# training_scores=np.zeros(N)\n",
        "# testing_scores=np.zeros(N)\n",
        "# neighbors=np.arange(1,11)\n",
        "\n",
        "# for d in range(1, 11):\n",
        "#     knn = KNeighborsClassifier(n_neighbors = d)\n",
        "#     knn.fit(x_train, y_train)\n",
        "#     y_pred=knn.predict(x_test)\n",
        "#     training_scores[d-1]=accuracy_score(y_pred,y_test)\n",
        "#     testing_scores[d-1]=accuracy_score(y_pred,y_test)\n",
        "    \n",
        "# print(training_scores,testing_scores)\n",
        "# fig, ax = plt.subplots(1, figsize = (10, 7))\n",
        "    \n",
        "# ax.scatter(neighbors,training_scores,color=\"black\",label=\"training\")\n",
        "# ax.scatter(neighbors,testing_scores,color=\"firebrick\",label=\"testing\")    \n",
        "# ax.set(xlabel = \"Complexity (depth)\", ylabel = \"Performance (score)\",ylim=(0,1))\n",
        "# ax.legend()\n",
        "\n",
        "KNN = KNeighborsClassifier()\n",
        "\n",
        "n_neighbors = range(1,15)\n",
        "# Create the random grid\n",
        "random_grid = {'n_neighbors': n_neighbors}\n",
        "grid_search=GridSearchCV(KNN,param_grid=random_grid)\n",
        "grid_search.fit(x_train,y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "GYRPdscx4jPa"
      },
      "id": "GYRPdscx4jPa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choose k=7\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn=KNeighborsClassifier(n_neighbors=6)\n",
        "knn.fit(x_train,y_train)\n",
        "y_pred=knn.predict(x_test)\n",
        "accuracy_score(y_pred,y_test)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['wakefulness','deep sedation'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred,target_names=['wakefulness','deep sedation']))"
      ],
      "metadata": {
        "id": "FlBWg-zm712K"
      },
      "id": "FlBWg-zm712K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "GNB = GaussianNB()\n",
        "GNB.fit(x_train, y_train)\n",
        "y_pred=GNB.predict(x_test)\n",
        "accuracy_score(y_pred,y_test)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['wakefulness','deep sedation'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred,target_names=['wakefulness','deep sedation']))"
      ],
      "metadata": {
        "id": "U-mkZhCy9ZmK"
      },
      "id": "U-mkZhCy9ZmK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "n_estimators = [90,100,115,130]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2, 10, 15, 20]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "criterion = ['gini','entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "\n",
        "\n",
        "RF = RandomForestClassifier()\n",
        "grid_search=RandomizedSearchCV(RF,random_grid)\n",
        "grid_search.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "QL4_12Xc-yHY"
      },
      "id": "QL4_12Xc-yHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "bQJJuJuQAfb2"
      },
      "id": "bQJJuJuQAfb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF=RandomForestClassifier(criterion='gini',\n",
        "                          max_depth=15,\n",
        "                          max_features='auto',\n",
        "                          min_samples_leaf=4,\n",
        "                          min_samples_split=5,\n",
        "                          n_estimators=130)\n",
        "# RF=RandomForestClassifier(criterion='entropy',\n",
        "#                           max_depth=10,\n",
        "#                           max_features='auto',\n",
        "#                           min_samples_leaf=4,\n",
        "#                           min_samples_split=10,\n",
        "#                           n_estimators=115)\n",
        "RF.fit(x_train,y_train)\n",
        "y_pred=RF.predict(x_test)\n",
        "\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['wakefulness','deep sedation'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred,target_names=['wakefulness','deep sedation']))\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xBoZWi9VAybM"
      },
      "id": "xBoZWi9VAybM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = RF.feature_importances_\n",
        "pd.DataFrame(features).to_csv(\"HudetzHoldoutRF4features.csv\")"
      ],
      "metadata": {
        "id": "Z2-sc0BIaln4"
      },
      "id": "Z2-sc0BIaln4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() #limit # of trainable parameters (conv2D provides limitations,takes less time than Dense layers would)"
      ],
      "metadata": {
        "id": "c8TruvCZSeKZ"
      },
      "id": "c8TruvCZSeKZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "expanded-image",
      "metadata": {
        "id": "expanded-image"
      },
      "source": [
        "Let's see how our model does over epochs! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1v6jsExdQbd",
      "metadata": {
        "id": "h1v6jsExdQbd"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"accuracy\"],label='training')\n",
        "plt.plot(history.history[\"val_accuracy\"],label='validation')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stuck-fifty",
      "metadata": {
        "id": "stuck-fifty"
      },
      "source": [
        "## Extracting Predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred,y_test"
      ],
      "metadata": {
        "id": "xSk720s54xGh"
      },
      "id": "xSk720s54xGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "democratic-column",
      "metadata": {
        "id": "democratic-column"
      },
      "source": [
        "Let's see how our model did on the test data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thirty-footage",
      "metadata": {
        "id": "thirty-footage"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classified-desert",
      "metadata": {
        "id": "classified-desert"
      },
      "source": [
        "We'll plot these predicted labels along side the (true labels). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "proprietary-corner",
      "metadata": {
        "id": "proprietary-corner"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "for i, num in enumerate([1, 3, 4, 5, 6, 11,14,16]):\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.reshape(x_test[num],(55,100)))\n",
        "    lab=int(y_test[num])\n",
        "    plt.xlabel(train_labels[int(y_pred[num])] + f\" ({train_labels[lab]})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Group Means\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3lU5VCANikNS"
      },
      "id": "3lU5VCANikNS"
    },
    {
      "cell_type": "code",
      "source": [
        "all_data=np.concatenate([all_data,all_test_data])\n",
        "all_labels=np.concatenate([all_labels,all_test_labels])"
      ],
      "metadata": {
        "id": "J-iQ32y_JRSf"
      },
      "id": "J-iQ32y_JRSf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wake=[]\n",
        "unconscious=[]\n",
        "recovery=[]\n",
        "\n",
        "for i, label in enumerate(all_labels):\n",
        "  if label==0:\n",
        "    wake.append(all_data[i])\n",
        "  elif label==1:\n",
        "    unconscious.append(all_data[i])\n",
        "  elif label==2:\n",
        "    recovery.append(all_data[i]) # if exists in data breakdown\n",
        "\n",
        "wake_mean = np.mean(np.array(wake),axis=0)\n",
        "unconscious_mean = np.mean(np.array(unconscious),axis=0)\n",
        "if len(recovery) != 0:\n",
        "  recovery_mean = np.mean(np.array(recovery),axis=0)"
      ],
      "metadata": {
        "id": "_og6QWKAjfl9"
      },
      "id": "_og6QWKAjfl9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wake"
      ],
      "metadata": {
        "id": "B2AiwwPeolSZ"
      },
      "id": "B2AiwwPeolSZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "el1 = [item[0] for item in wake]\n",
        "el1\n",
        "\n",
        "# el2=[item[15] for item in unconscious]\n",
        "# el2\n",
        "\n",
        "# variance(el2)/variance(el1)"
      ],
      "metadata": {
        "id": "ru5uuCFaqHMz"
      },
      "id": "ru5uuCFaqHMz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(el1,el2)"
      ],
      "metadata": {
        "id": "DvcEb7v63qXB"
      },
      "id": "DvcEb7v63qXB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttest_ind_results = []\n",
        "\n",
        "for i in (range(len(all_data[0]))):\n",
        "  wake_i = [item[i] for item in wake]\n",
        "  unconscious_i = [item[i] for item in unconscious]\n",
        "\n",
        "  #T TEST ASSUMPTIONS: independent samples, random sampling, normal distribution -> mann whitney u test? \n",
        "  #independent or dependent?\n",
        "  #t.test - welsh's or pooled (check variance of wake/unconscious), paired or no, FDR correction\n",
        "  #equal var True (Student's), independent?, FDR correction\n",
        "  #ASSESS SIGNIFICANCE - compare t tests? across all 1500 cols? (check robyn paper, IEEE paper) -> return sig cols? \n",
        "  #(is there a diff between cols)\n",
        "\n",
        "  ttest_ind_results.append(stats.ttest_ind(wake_i,unconscious_i))\n",
        "\n",
        "#print(sig_cols)\n"
      ],
      "metadata": {
        "id": "b8-cIX73sOHe"
      },
      "id": "b8-cIX73sOHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pvals=[]\n",
        "\n",
        "for result in ttest_ind_results:\n",
        "  pvals.append(result[1])"
      ],
      "metadata": {
        "id": "otQVKcTc48_7"
      },
      "id": "otQVKcTc48_7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pvals"
      ],
      "metadata": {
        "id": "p3kqDnBr7WiI"
      },
      "id": "p3kqDnBr7WiI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.multitest import fdrcorrection\n",
        "adjustedps = fdrcorrection(pvals,alpha=0.1)"
      ],
      "metadata": {
        "id": "Z-EZdGQN53JW"
      },
      "id": "Z-EZdGQN53JW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjustedps"
      ],
      "metadata": {
        "id": "iydp-OHrA0-T"
      },
      "id": "iydp-OHrA0-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,val in enumerate(adjustedps[0]):\n",
        "  if val==True:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "OzCXR0Xx6rBy"
      },
      "id": "OzCXR0Xx6rBy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize group mean STSPs\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(np.reshape(wake_mean,(55,100)))\n",
        "plt.xlabel(\"wake\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(np.reshape(unconscious_mean,(55,100)))\n",
        "plt.xlabel(\"unconscious\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rmSgcxZ3k_30"
      },
      "id": "rmSgcxZ3k_30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "norman-concentration",
      "metadata": {
        "id": "norman-concentration"
      },
      "source": [
        "# Visualizing Learned Features \n",
        "\n",
        "It's possible to define a separate model that allows us to study the features learned by the model. These are often called *activations*. We create this model by simply asserting that the model outputs are equal to the outputs of the first convolutional layer. For this we use the `models.Model` class rather than the `models.Sequential` class, which is more convenient but less flexible. \n",
        "\n",
        "It's possible to look at the activations at different levels of the model. Generally speaking, it is expected that the activations become more abstract as one goes higher up the model structure. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominant-lover",
      "metadata": {
        "id": "dominant-lover"
      },
      "outputs": [],
      "source": [
        "#only looking at outputs of first layer\n",
        "\n",
        "activation_model=models.Model(inputs=SVC.input,outputs=SVC.layers[0].output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "static-jacket",
      "metadata": {
        "id": "static-jacket"
      },
      "source": [
        "Now we can compute the activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organized-nudist",
      "metadata": {
        "id": "organized-nudist"
      },
      "outputs": [],
      "source": [
        "activations=activation_model.predict(train_images[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "restricted-mortality",
      "metadata": {
        "id": "restricted-mortality"
      },
      "source": [
        "And visualize them! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "laughing-advancement",
      "metadata": {
        "id": "laughing-advancement"
      },
      "outputs": [],
      "source": [
        "k = 7\n",
        "\n",
        "color_im = x_train[k:(k+1)]\n",
        "convd = conv(color_im).numpy()\n",
        "\n",
        "fig, axarr = plt.subplots(3, 3, figsize = (8, 6))\n",
        "\n",
        "axarr[0, 0].imshow(color_im[0])\n",
        "axarr[0,0].axis(\"off\")\n",
        "axarr[0,0].set(title = \"Original\")\n",
        "\n",
        "i = 0\n",
        "for ax in axarr.flatten()[1:]:\n",
        "    ax.imshow(activations[k,:,:,i], cmap = \"gray\")\n",
        "    i += 1\n",
        "    ax.axis(\"off\")\n",
        "    ax.set(title = \"Feature \" + str(i))\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oriented-advocacy",
      "metadata": {
        "id": "oriented-advocacy"
      },
      "source": [
        "Somewhat romantically, these activations might be interpreted as \"how the algorithm looks at\" the resulting image. That said, one must be careful of over-interpretation. Still, it looks like some of the features correspond to edge detection (like we saw above), while others correspond to highlighting different patches of colors, enabling, for example, separation of the foreground object from the background. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}